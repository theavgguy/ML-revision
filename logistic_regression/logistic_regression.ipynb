{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "dim = 28*28 + 1\n",
    "batch_size = 128\n",
    "lr = 0.05\n",
    "iterations= 201\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "mnist = input_data.read_data_sets(\"MNIST-data\", one_hot=False)\n",
    "x_, y_ = mnist.train.next_batch(60000)\n",
    "x_test,y_test = mnist.test.next_batch(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for binary classifier extract samples of 2 classes\n",
    "def dataset(label1,label2):\n",
    "    Y = []\n",
    "    X = []\n",
    "    for e in range(60000):\n",
    "        if y_[e]==label1:\n",
    "            Y.append(0)\n",
    "            X.append(x_[e])\n",
    "        elif y_[e]==label2:\n",
    "            Y.append(1)\n",
    "            X.append(x_[e])\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "\n",
    "    test_Y = []\n",
    "    test_X = []\n",
    "    for e in range(10000):\n",
    "        if y_test[e]==label1:\n",
    "            test_Y.append(0)\n",
    "            test_X.append(x_test[e])\n",
    "        elif y_test[e]==label2:\n",
    "            test_Y.append(1)\n",
    "            test_X.append(x_test[e])\n",
    "    test_X = np.asarray(test_X)\n",
    "    test_Y = np.asarray(test_Y)\n",
    "    \n",
    "    return X,Y,test_X,test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a bias dimension to features\n",
    "def bias_transform(label1,label2):\n",
    "    X,Y,test_X,test_Y = dataset(label1,label2)\n",
    "    X = np.insert(X,len(X[0]),1,axis=1)\n",
    "    test_X = np.insert(test_X,len(test_X[0]),1,axis=1)\n",
    "    train_total = len(X)\n",
    "    train_epochs = int(train_total/batch_size)\n",
    "    test_total = len(test_X)\n",
    "    test_epochs = int(test_total/batch_size)\n",
    "    \n",
    "    return X,Y,test_X,test_Y,train_epochs,test_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "def weights_init():\n",
    "    W = np.random.rand(dim)\n",
    "    W = W/1000\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward prop\n",
    "def sigmoid(x):\n",
    "    val = 1./(1.+np.exp(-x))\n",
    "    return val\n",
    "\n",
    "def forward_prop(X,W):\n",
    "    logits = np.dot(X,W)\n",
    "    return sigmoid(logits)\n",
    "\n",
    "#loss function and gradients\n",
    "def BCE_loss(activations,labels):\n",
    "    cost1 = np.ones(len(activations))\n",
    "    cost2 = np.ones(len(activations))\n",
    "    for e in range(len(activations)):\n",
    "        cost1[e] = labels[e]*np.log(activations[e])\n",
    "        cost2[e] = (1-labels[e])*(1-np.log(activations[e]))\n",
    "    cost = np.add(cost1,cost2)\n",
    "    cost = cost.sum()\n",
    "    cost = (-1/len(activations))*cost\n",
    "    return cost\n",
    "\n",
    "def gradient(p,t,X):\n",
    "    if len(p)==0:\n",
    "        print(\"len error in predictions\")\n",
    "    error = p - t\n",
    "    gradients = np.dot(X.T,error)\n",
    "    gradients = np.multiply(gradients,(lr/len(p)))\n",
    "    return gradients\n",
    "\n",
    "def update_rule(G,W):\n",
    "    for e in G:\n",
    "        if e==\"nan\":\n",
    "            print(\"gradient explode\")\n",
    "    W = W - G\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for validation and accuracy calculation\n",
    "def classes(predictions,labels):\n",
    "    acc = 0\n",
    "    for v in range(len(predictions)):\n",
    "        if predictions[v]>=threshold and labels[v]==1:\n",
    "            acc+=1\n",
    "        elif predictions[v]<=threshold and labels[v]==0:\n",
    "            acc+=1\n",
    "    return (acc/len(labels))*100\n",
    "    \n",
    "def validation(test_epochs,test_X,test_Y,W):\n",
    "    accuracy = 0\n",
    "    for j in range(test_epochs):\n",
    "        test = test_X[batch_size*j:batch_size*(j+1)]\n",
    "        labels = test_Y[batch_size*j:batch_size*(j+1)]\n",
    "        predictions = forward_prop(test,W)\n",
    "        accuracy = accuracy+classes(predictions,labels)\n",
    "    return accuracy/test_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(label1, label2):\n",
    "    #setup data\n",
    "    X,Y,test_X,test_Y,train_epochs,test_epochs = bias_transform(label1,label2)\n",
    "    W = weights_init()\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    itx = []\n",
    "    for i in range(iterations):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for j in range(train_epochs):\n",
    "            train = X[batch_size*j:batch_size*(j+1)]\n",
    "            labels = Y[batch_size*j:batch_size*(j+1)]\n",
    "            predictions = forward_prop(train,W)\n",
    "            g = gradient(predictions,labels,train)\n",
    "            W = update_rule(g,W)\n",
    "            loss = loss+BCE_loss(predictions,labels)\n",
    "            acc = acc+classes(predictions,labels)\n",
    "        losses.append(loss/train_epochs)\n",
    "        accuracies.append(acc/train_epochs)\n",
    "        itx.append(i)\n",
    "        if i%10==0:\n",
    "            #print(\"gradients\",g)\n",
    "            print(\"iteration =\",i)\n",
    "            print(\"loss ={0:.2f}\".format(losses[-1]))\n",
    "            print(\"training accuracy ={0:.2f}\".format(accuracies[-1]))\n",
    "        if i%30==0:\n",
    "            print(\"validation set accuracy ={0:.2f}\".format(validation(test_epochs,test_X,test_Y,W)))\n",
    "    return losses, accuracies, itx, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\n",
      "loss =-1.24\n",
      "training accuracy =91.20\n",
      "validation set accuracy =95.16\n",
      "iteration = 10\n",
      "loss =-2.64\n",
      "training accuracy =96.19\n",
      "iteration = 20\n",
      "loss =-2.93\n",
      "training accuracy =96.59\n",
      "iteration = 30\n",
      "loss =-3.10\n",
      "training accuracy =96.83\n",
      "validation set accuracy =96.82\n",
      "iteration = 40\n",
      "loss =-3.20\n",
      "training accuracy =96.94\n",
      "iteration = 50\n",
      "loss =-3.28\n",
      "training accuracy =97.08\n",
      "iteration = 60\n",
      "loss =-3.34\n",
      "training accuracy =97.15\n",
      "validation set accuracy =96.88\n",
      "iteration = 70\n",
      "loss =-3.39\n",
      "training accuracy =97.19\n",
      "iteration = 80\n",
      "loss =-3.44\n",
      "training accuracy =97.26\n",
      "iteration = 90\n",
      "loss =-3.47\n",
      "training accuracy =97.30\n",
      "validation set accuracy =96.82\n",
      "iteration = 100\n",
      "loss =-3.50\n",
      "training accuracy =97.35\n",
      "iteration = 110\n",
      "loss =-3.53\n",
      "training accuracy =97.37\n",
      "iteration = 120\n",
      "loss =-3.56\n",
      "training accuracy =97.36\n",
      "validation set accuracy =96.67\n",
      "iteration = 130\n",
      "loss =-3.58\n",
      "training accuracy =97.37\n",
      "iteration = 140\n",
      "loss =-3.60\n",
      "training accuracy =97.35\n",
      "iteration = 150\n",
      "loss =-3.62\n",
      "training accuracy =97.35\n",
      "validation set accuracy =96.72\n",
      "iteration = 160\n",
      "loss =-3.64\n",
      "training accuracy =97.38\n",
      "iteration = 170\n",
      "loss =-3.65\n",
      "training accuracy =97.39\n",
      "iteration = 180\n",
      "loss =-3.67\n",
      "training accuracy =97.40\n",
      "validation set accuracy =96.77\n",
      "iteration = 190\n",
      "loss =-3.68\n",
      "training accuracy =97.43\n",
      "iteration = 200\n",
      "loss =-3.70\n",
      "training accuracy =97.44\n"
     ]
    }
   ],
   "source": [
    "losses,accuracies,itx,W = train(3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bd2b9598d0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(itx,losses,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\Anaconda3\\envs\\tf1.12\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit score:  99.74515800203874\n"
     ]
    }
   ],
   "source": [
    "# Scikit Logistic Regression\n",
    "X,Y,test_X,test_Y = dataset(0,4)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X,Y)\n",
    "\n",
    "#Score is Mean Accuracy\n",
    "scikit_score = clf.score(test_X,test_Y)\n",
    "print ('Scikit score: ', 100*scikit_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
